#include <catch2/catch_test_macros.hpp>

#include "linear_regression_model.h"

TEST_CASE("Name is lesstimate", "[library]")
{


  arma::mat X = {{1, -0.56, -0.23, 1.559, 0.071, 0.129, 1.715, 0.461, -1.265, -0.687, -0.446},
  {1, 1.224, 0.36, 0.401, 0.111, -0.556, 1.787, 0.498, -1.967, 0.701, -0.473},
  {1, -1.068, -0.218, -1.026, -0.729, -0.625, -1.687, 0.838, 0.153, -1.138, 1.254},
  {1, 0.426, -0.295, 0.895, 0.878, 0.822, 0.689, 0.554, -0.062, -0.306, -0.38},
  {1, -0.695, -0.208, -1.265, 2.169, 1.208, -1.123, -0.403, -0.467, 0.78, -0.083},
  {1, 0.253, -0.029, -0.043, 1.369, -0.226, 1.516, -1.549, 0.585, 0.124, 0.216},
  {1, 0.38, -0.502, -0.333, -1.019, -1.072, 0.304, 0.448, 0.053, 0.922, 2.05},
  {1, -0.491, -2.309, 1.006, -0.709, -0.688, 1.026, -0.285, -1.221, 0.181, -0.139},
  {1, 0.006, 0.385, -0.371, 0.644, -0.22, 0.332, 1.097, 0.435, -0.326, 1.149},
  {1, 0.994, 0.548, 0.239, -0.628, 1.361, -0.6, 2.187, 1.533, -0.236, -1.026},
  {1, -0.71, 0.257, -0.247, -0.348, -0.952, -0.045, -0.785, -1.668, -0.38, 0.919},
  {1, -0.575, 0.608, -1.618, -0.056, 0.519, 0.301, 0.106, -0.641, -0.85, -1.024},
  {1, 0.118, -0.947, -0.491, -0.256, 1.844, -0.652, 0.235, 0.078, -0.962, -0.071},
  {1, 1.445, 0.452, 0.041, -0.422, -2.053, 1.131, -1.461, 0.74, 1.909, -1.444},
  {1, 0.702, -0.262, -1.572, -1.515, -1.602, -0.531, -1.462, 0.688, 2.1, -1.287},
  {1, 0.788, 0.769, 0.332, -1.008, -0.119, -0.28, 0.563, -0.372, 0.977, -0.375},
  {1, 1.053, -1.049, -1.26, 3.241, -0.417, 0.298, 0.637, -0.484, 0.517, 0.369},
  {1, -0.215, 0.065, -0.034, 2.128, -0.741, -1.096, 0.038, 0.31, 0.437, -0.458},
  {1, -1.063, 1.263, -0.35, -0.866, -0.236, -0.197, 1.11, 0.085, 0.754, -0.499},
  {1, 0.214, -0.325, 0.095, -0.895, -1.311, 1.997, 0.601, -1.251, -0.611, -1.185},
  {1, 2.199, 1.312, -0.265, 0.543, -0.414, -0.476, -0.789, -0.595, 1.651, -0.054},
  {1, 0.119, 0.244, 1.232, -0.516, -0.993, 1.676, -0.441, -0.723, -1.236, -1.285},
  {1, -0.574, 0.618, 1.11, 0.708, -0.364, 0.06, -0.705, -0.717, 0.885, -1.016},
  {1, 1.955, -0.09, 0.215, -0.739, -0.574, -1.317, -0.183, 0.419, 0.324, -0.782},
  {1, -0.789, -0.502, 1.496, -1.137, -0.179, 1.902, -0.101, -1.36, -0.665, 0.485},
  {1, -0.376, -0.562, -0.344, 0.09, 1.599, -0.089, 1.081, 0.631, -0.114, -1.533},
  {1, -0.521, -0.49, 0.047, 1.3, 2.293, 1.548, -0.133, -1.757, -0.389, 0.089},
  {1, 0.845, 0.963, 0.684, -1.395, 0.85, -0.447, 0.175, 0.075, 0.428, 0.025},
  {1, -1.667, 0.736, 0.386, -0.266, 0.118, 0.134, 0.221, 1.641, -0.219, 0.168},
  {1, 1.168, 1.054, 1.145, -0.577, 2.002, 0.067, 1.867, -1.351, 0.021, 1.25},
  {1, -0.715, -0.753, -0.939, -1.053, -0.437, 0.331, -2.014, 0.212, 1.237, 2.038},
  {1, 1.301, 0.757, -1.727, -0.602, -0.352, 0.704, -0.106, -1.259, 1.684, 0.911},
  {1, 0.237, 1.218, -1.339, 0.661, -0.523, 0.684, -0.061, 0.633, 1.336, 0.007},
  {1, 1.018, -1.188, -0.722, 1.519, 0.377, -2.052, -1.364, -0.201, 0.866, -0.102},
  {1, 0.624, 0.959, 1.671, 0.056, -0.052, -1.753, 0.099, -0.572, -0.974, -0.18},
  {1, 1.015, -1.993, -0.427, 0.117, -0.893, 0.334, 0.411, -0.033, -2.466, 2.571},
  {1, -0.205, 0.651, 0.274, 1.025, 0.818, -0.21, 0.378, -0.945, 0.857, -0.461},
  {1, 2.417, -1.651, -0.464, 0.825, 0.51, -0.589, -0.997, 0.144, -0.014, -1.79},
  {1, 0.035, 0.19, 0.175, -1.055, 0.476, 1.379, 0.456, -1.136, -0.436, 0.346},
  {1, -0.647, -2.158, 0.884, -0.829, -0.574, 1.504, -0.774, 0.846, -1.261, -0.355},
  {1, -0.074, -1.169, -0.635, -0.029, 0.671, -1.651, -0.35, 0.756, -0.539, 0.227},
  {1, 0.492, 0.268, 0.653, -0.123, -0.414, -2.643, -0.093, 0.43, 0.535, -0.555},
  {1, 1.78, 0.286, 0.126, 1.272, -0.718, -0.45, 2.397, 0.011, 1.634, -1.439},
  {1, -0.191, 0.378, 0.3, -1.006, 0.019, -1.077, 0.713, 1.085, -2.225, 1.236},
  {1, -1.241, 0.455, 0.66, -0.2, -0.645, 0.165, 0.439, 0.883, -2.052, -1.636},
  {1, 1.43, 1.047, 0.435, 0.715, 0.917, -2.661, 1.11, -0.485, 0.231, -0.295},
  {1, 0.872, -0.348, 0.519, -0.391, -1.093, 1.21, 0.741, 1.724, 0.065, 1.125},
  {1, 1.975, -0.281, -1.323, -0.239, -0.214, 0.152, 1.712, -0.326, 0.373, -0.228},
  {1, 0.02, 0.314, 1.328, 0.121, 0.713, 0.779, 0.915, -0.574, 1.627, -0.381},
  {1, -0.106, 1.404, 1.294, -1.09, -0.873, -1.358, 0.182, 0.165, 0.364, 0.552},
  };

  arma::colvec y = {{0.326},
  {0.09},
  {-2.466},
  {1.48},
  {2.031},
  {1.864},
  {-1.82},
  {-3.315},
  {1.323},
  {1.365},
  {-1.901},
  {-0.213},
  {0.734},
  {-1.054},
  {-4.406},
  {0.184},
  {1.933},
  {1.043},
  {-0.169},
  {-2.009},
  {0.595},
  {-2.832},
  {3.366},
  {0.75},
  {-1.212},
  {0.187},
  {1.933},
  {1.464},
  {-1.209},
  {2.739},
  {-2.05},
  {-1.484},
  {0.718},
  {2.084},
  {2.529},
  {-1.467},
  {0.247},
  {0.64},
  {-1.243},
  {-2.973},
  {-1.168},
  {-1.668},
  {1.582},
  {-1.997},
  {-1.897},
  {3.789},
  {-0.616},
  {-1.023},
  {2.134},
  {0.384},
  };

  // result from glmnet
  arma::rowvec expect = {-0.10045259559648, 0.257855768583206, 0.484754028966191, 0.228258393175188, 0.827655310648628, 0.648025353841178, 0, 0, 0, 0.000830669596111546, 0};

  unsigned int n_par = X.n_cols;

  linearRegressionModel linReg(y, X);
  linearRegressionModelNumericGradients linRegNumGrad(y, X);

  arma::rowvec startingValues(n_par);
  startingValues.fill(0.0);

  std::vector<std::string> labels{"b0", "b1", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b9", "b10"};
  less::stringVector parameterLabels(labels);

  // penalty: We don't penalize the intercept b0, but we penalize
  // b1 and b2 with lasso:
  std::vector<std::string> penalty{"none", "lasso", "lasso", "lasso", "lasso", "lasso", "lasso", "lasso", "lasso", "lasso", "lasso"};

  // tuning parameter lambda:
  arma::rowvec lambda = {{0.0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2}};
  // theta is not used by the lasso penalty:
  arma::rowvec theta = {{0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}};

  less::fitResults fitResultGlmnet = less::fitGlmnet(
      linReg,
      startingValues,
      parameterLabels,
      penalty,
      lambda,
      theta //,
      // initialHessian, // optional, but can be very useful
  );

  for(unsigned int i = 0; i < expect.n_elem; i++)
    REQUIRE(std::abs(fitResultGlmnet.parameterValues(i)-expect(i)) < 0.0001);


  less::fitResults fitResultGlmnetNumGrad = less::fitGlmnet(
          linRegNumGrad,
          startingValues,
          parameterLabels,
          penalty,
          lambda,
          theta //,
          // initialHessian, // optional, but can be very useful
      );

  for(unsigned int i = 0; i < expect.n_elem; i++)
    REQUIRE(std::abs(fitResultGlmnetNumGrad.parameterValues(i)-expect(i)) <= 0.001);


less::fitResults fitResultIsta = less::fitIsta(
        linReg,
        startingValues,
        parameterLabels,
        penalty,
        lambda,
        theta);


for(unsigned int i = 0; i < expect.n_elem; i++)
  REQUIRE(std::abs(fitResultIsta.parameterValues(i)-expect(i)) <= 0.001);


    less::fitResults fitResultIstaNumGrad = less::fitIsta(
        linRegNumGrad,
        startingValues,
        parameterLabels,
        penalty,
        lambda,
        theta);
for(unsigned int i = 0; i < expect.n_elem; i++)
  REQUIRE(std::abs(fitResultIstaNumGrad.parameterValues(i)-expect(i)) <= 0.001);
}
